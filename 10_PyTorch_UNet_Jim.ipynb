{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.9"
    },
    "colab": {
      "name": "10_PyTorch_UNet_Jim.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZalennMQ54nE",
        "colab_type": "text"
      },
      "source": [
        "# Assignment 10 - UNet\n",
        "\n",
        "In this assignement we are going to program our own UNet network (https://arxiv.org/pdf/1505.04597.pdf) which is a simple but powerful one. This network is made to produce a segmentation map. This segmentation map can be a little bit smaller than the true map but keep the same spatial structure. This map however is composed of several layers, one per class. The goal for the network is to activate pixel-wisely a layer if the pixel are representing the object of the layer."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uarH9tze54nN",
        "colab_type": "code",
        "outputId": "a182e6fb-4000-47f0-fcf2-5f63207d85ad",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 488
        }
      },
      "source": [
        "from IPython.display import Image\n",
        "from IPython.core.display import HTML \n",
        "Image(url= \"https://lmb.informatik.uni-freiburg.de/people/ronneber/u-net/u-net-architecture.png\", width=700)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<img src=\"https://lmb.informatik.uni-freiburg.de/people/ronneber/u-net/u-net-architecture.png\" width=\"700\"/>"
            ],
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lpZG9dBJ54nj",
        "colab_type": "text"
      },
      "source": [
        "The network look this way. The descending part is simply made out of convolution layer and pooling, easy peasy. This part of the network allow a move from the \"Where?\" information to the \"What?\" information. Then the informations are spatially dilated through a so called \"transpose convolution\" looking like a convoltuion mixed with an inverse pooling and then you convolute. as I sayed above, there is one layer of exit per class, don't trust the drawing, the initial version of this network was only design to say yes or not (That why there is two output layer)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1Uh9i-W454ns",
        "colab_type": "code",
        "outputId": "a3cb7d8e-6cdc-479d-88c2-9e0f759aed97",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 353
        }
      },
      "source": [
        "Image(url= \"https://miro.medium.com/max/3200/0*mk6U6zQDuoQLK7Ca\", width=700)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<img src=\"https://miro.medium.com/max/3200/0*mk6U6zQDuoQLK7Ca\" width=\"700\"/>"
            ],
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MbkcMVll54n8",
        "colab_type": "text"
      },
      "source": [
        "After each big step of convolution, the informations are stacked to the last part of the network (grey arrow) reinjecting this way the \"Where?\" information.\n",
        "\n",
        "# 8.1\n",
        "\n",
        "Yo have to reproduce this network by yourself. The images takken for this work come from the PascalVOC database (http://host.robots.ox.ac.uk/pascal/VOC/). Here you inject RGB images into your network and out a \"cube\" of maps. The label of the data are on the shape of images with one channel, the background is represented by 0 and the differents class by a unique label (all the pixel filled out of ones are representing a plan typically.)\n",
        "\n",
        "You have to use dtype=torch.float32 for the images and dtype=torch.long for the mask and every thing should run perfectly. Use also the criterion to use should be criterion = nn.CrossEntropyLoss() because he can understand the type of label injected (https://pytorch.org/docs/stable/nn.html#torch.nn.CrossEntropyLoss). \n",
        "\n",
        "Try to work on this early, the training can be slow (like 1h for 50 epoch ; batch : 100)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A7wuyHJy54n_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "cfe091ff-51c4-4d7e-c3d9-62b4d91c460f"
      },
      "source": [
        "import copy\n",
        "import os\n",
        "import sys\n",
        "import time\n",
        "\n",
        "import numpy as np\n",
        "from matplotlib import pyplot as plt\n",
        "from PIL import Image\n",
        "import torch\n",
        "import torchvision\n",
        "import torch.nn as nn\n",
        "from torch import optim\n",
        "from torch.optim import lr_scheduler\n",
        "import torch.nn.functional as F\n",
        "from torch.autograd import Function\n",
        "from torch.utils.data import DataLoader, random_split\n",
        "from tqdm import tqdm\n",
        "\n",
        "\n",
        "np.set_printoptions(threshold=sys.maxsize)\n",
        "print(torch.__version__)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1.3.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8AK2yV7C54oL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class VOCSegLoader(torchvision.datasets.VOCSegmentation):\n",
        "    def __init__(self, \n",
        "                 root, \n",
        "                 year='2012',\n",
        "                 image_set='train',\n",
        "                 download=False,\n",
        "                 transform=None,\n",
        "                 target_transform=None,\n",
        "                 transforms=None):\n",
        "        \n",
        "        super(VOCSegLoader, self).__init__(root, year, image_set, download, transform, target_transform, transforms)\n",
        "\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            index (int): Index\n",
        "\n",
        "        Returns:\n",
        "            tuple: (image, target) where target is the image segmentation.\n",
        "        \"\"\"\n",
        "        img = Image.open(self.images[index]).convert('RGB')\n",
        "        target = Image.open(self.masks[index])\n",
        "        \n",
        "        target = np.array(target)\n",
        "        target[target == 255] = 0\n",
        "        target = Image.fromarray(target)\n",
        "        \n",
        "        if self.transforms is not None:\n",
        "            img, target = self.transforms(img, target)\n",
        "        \n",
        "        target = torch.as_tensor(np.asarray(target, dtype=np.uint8), dtype=torch.long)\n",
        "        return img, target          "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U8RwKyj454oW",
        "colab_type": "code",
        "outputId": "0f3b0d13-0ff4-41db-b2c5-e3b5df66c39c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "n_epochs = 3\n",
        "batch_size_train = 100\n",
        "batch_size_val = 100\n",
        "learning_rate = 0.001\n",
        "momentum = 0.9\n",
        "log_interval = 10\n",
        "image_size = (64, 85)\n",
        "\n",
        "\n",
        "transform_data = torchvision.transforms.Compose([torchvision.transforms.Resize(image_size), \n",
        "                                                 torchvision.transforms.ToTensor()])\n",
        "transform_label = torchvision.transforms.Compose([torchvision.transforms.Resize(image_size, interpolation=0)])\n",
        "\n",
        "\n",
        "train_dataset = VOCSegLoader('./data', year='2012', image_set='train', download=True,\n",
        "                                         transform=transform_data, target_transform=transform_label)\n",
        "val_dataset = VOCSegLoader('./data', year='2012', image_set='val', download=True,\n",
        "                                         transform=transform_data , target_transform=transform_label)\n",
        "dataset_sizes = {\n",
        "    'train': len(train_dataset),\n",
        "    'val': len(val_dataset),\n",
        "}\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size_train, num_workers=4)\n",
        "val_loader = torch.utils.data.DataLoader(val_dataset, batch_size=batch_size_val, num_workers=4)\n",
        "dataloaders = {\n",
        "    'train': train_loader,\n",
        "    'val': val_loader,\n",
        "}\n",
        "\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using downloaded and verified file: ./data/VOCtrainval_11-May-2012.tar\n",
            "Using downloaded and verified file: ./data/VOCtrainval_11-May-2012.tar\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qJPC0nGx54og",
        "colab_type": "code",
        "outputId": "db42919a-846e-4d8b-dfd7-a09a0ea0a613",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 302
        }
      },
      "source": [
        "image, target = train_dataset[0]\n",
        "print(type(image), image.size())\n",
        "print(type(target), target.size())\n",
        "\n",
        "plt.figure()\n",
        "plt.imshow(image.numpy()[0,:,:])\n",
        "plt.imshow(np.asarray(target))\n",
        "plt.show()\n",
        "\n",
        "def imshow(inp, title=None):\n",
        "    inp = inp.numpy().transpose((1, 2, 0))\n",
        "    plt.figure(figsize=(20, 20))\n",
        "    plt.axis('off')\n",
        "    plt.imshow(inp)\n",
        "    if title is not None:\n",
        "        plt.title(title)\n",
        "    plt.pause(0.001)\n",
        "\n",
        "def show_databatch(inputs):\n",
        "    out = torchvision.utils.make_grid(inputs)\n",
        "    #print(out.numpy())\n",
        "    imshow(out)\n",
        "\n",
        "# show_databatch([train_dataset[0][0], train_dataset[1][0]])\n",
        "# show_databatch([image, target])"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'torch.Tensor'> torch.Size([3, 64, 85])\n",
            "<class 'torch.Tensor'> torch.Size([64, 85])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAUIAAAD7CAYAAAAfH52VAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r_2pTfKw54op",
        "colab_type": "code",
        "outputId": "a1a52e47-2bc7-444e-990b-17214028d347",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        }
      },
      "source": [
        "# NETWORK\n",
        "from dataclasses import dataclass\n",
        "\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "\n",
        "DOWN = 1\n",
        "UP = 2\n",
        "\n",
        "class Concat(nn.Module):\n",
        "    def forward(self, x):\n",
        "        return \n",
        "\n",
        "class UNet(nn.Module):\n",
        "    \"\"\"\n",
        "    https://github.com/bigmb/Unet-Segmentation-Pytorch-Nest-of-Unets/blob/master/Models.py\n",
        "    \"\"\"\n",
        "    in_channels = 1\n",
        "    out_channels = 21\n",
        "    depth = 5\n",
        "    depth0_out_channels = 64\n",
        "    conv_kwargs = dict(\n",
        "        kernel_size=3,\n",
        "        # stride=1,\n",
        "        # padding=1,\n",
        "        # bias=True,\n",
        "    )\n",
        "    up_conv_kwargs = dict(\n",
        "        kernel_size=2,\n",
        "        # stride=1,\n",
        "        # padding=1,\n",
        "        # bias=True,\n",
        "    )\n",
        "\n",
        "    _maxpool = None\n",
        "\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "\n",
        "        self.tensor_depths = [\n",
        "            self.depth0_out_channels * 2**i\n",
        "            for i in range(self.depth)\n",
        "        ]\n",
        "\n",
        "        self.down_blocks = [\n",
        "            self.down_block(depth=i)\n",
        "            for i in range(self.depth)\n",
        "        ]\n",
        "        # self.DOWN = nn.Sequential(*self.down_blocks)\n",
        "        self.up_blocks = [\n",
        "            self.up_block(depth=i)\n",
        "            for i in range(self.depth - 1)\n",
        "        ]\n",
        "        # self.UP = nn.Sequential(*self.up_blocks)\n",
        "        self.last_conv = nn.Conv2d(self.depth0_out_channels, self.out_channels, 1)\n",
        "\n",
        "\n",
        "        # self.conv1 = nn.Conv2d(1, 64, 3)\n",
        "        # self.conv2 = nn.Conv2d(64, 64, 3)\n",
        "\n",
        "        # # self.maxpool = nn.MaxPool2d(2, 2)\n",
        "\n",
        "        # self.conv3 = nn.Conv2d(64, 128, 3)\n",
        "        # self.conv4 = nn.Conv2d(128, 128, 3)\n",
        "\n",
        "        # self.conv5 = nn.Conv2d(128, 256, 3)\n",
        "        # self.conv6 = nn.Conv2d(256, 256, 3)\n",
        "\n",
        "        # self.conv7 = nn.Conv2d(256, 512, 3)\n",
        "        # self.conv8 = nn.Conv2d(512, 512, 3)\n",
        "\n",
        "        # self.conv9 = nn.Conv2d(512, 1024, 3)\n",
        "        # self.conv10 = nn.Conv2d(1024, 1024, 3)\n",
        "\n",
        "        # self.upconv1 = nn.ConvTranspose2d(1024, 512, 2)\n",
        "        # # cat\n",
        "        # self.conv11 = nn.Conv2d(1024, 512, 3)\n",
        "        # self.conv12 = nn.Conv2d(512, 512, 3)\n",
        "\n",
        "        # self.upconv2 = nn.ConvTranspose2d(512, 256, 2)\n",
        "        # # cat\n",
        "        # self.conv13 = nn.Conv2d(512, 256, 3)\n",
        "        # self.conv14 = nn.Conv2d(256, 256, 3)\n",
        "\n",
        "        # self.upconv3 = nn.ConvTranspose2d(256, 128, 2)\n",
        "        # # cat\n",
        "        # self.conv15 = nn.Conv2d(256, 128, 3)\n",
        "        # self.conv16 = nn.Conv2d(128, 128, 3)\n",
        "\n",
        "        # self.upconv4 = nn.ConvTranspose2d(128, 64, 2)\n",
        "        # # cat\n",
        "        # self.conv17 = nn.Conv2d(128, 64, 3)\n",
        "        # self.conv18 = nn.Conv2d(64, 64, 3)\n",
        "\n",
        "        # self.conv19 = nn.Conv2d(64, 21, 1)\n",
        "\n",
        "    @property\n",
        "    def maxpool(self):\n",
        "        if not self._maxpool:\n",
        "            self._maxpool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "        return self._maxpool\n",
        "    \n",
        "    def down_block(self, depth):\n",
        "        in_ch = self.tensor_depths[depth - 1] if depth > 0 else self.in_channels\n",
        "        out_ch = self.tensor_depths[depth]\n",
        "        \n",
        "        args = [\n",
        "            nn.Conv2d(in_ch, out_ch, **self.conv_kwargs),\n",
        "            # nn.BatchNorm2d(out_ch),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(out_ch, out_ch, **self.conv_kwargs),\n",
        "            # nn.BatchNorm2d(out_ch),\n",
        "            nn.ReLU(inplace=True),\n",
        "        ]\n",
        "        if depth < self.depth - 1:\n",
        "            args.append(self.maxpool)\n",
        "        return nn.Sequential(*args)\n",
        "    \n",
        "    def up_block(self, depth):\n",
        "        in_ch = self.tensor_depths[depth]\n",
        "        out_ch = self.tensor_depths[depth - 1]\n",
        "        \"\"\"\n",
        "        f = self.upconv1(e)\n",
        "        f = torch.cat((d,f),dim=1)\n",
        "        f = F.relu(self.conv11(f))\n",
        "        f = F.relu(self.conv12(f))\n",
        "        \"\"\"\n",
        "        return (\n",
        "            nn.ConvTranspose2d(in_ch, out_ch, **self.up_conv_kwargs),\n",
        "            nn.Sequential(\n",
        "                nn.Conv2d(in_ch, out_ch, **self.conv_kwargs),\n",
        "                nn.ReLU(inplace=True),\n",
        "                nn.Conv2d(out_ch, out_ch, **self.conv_kwargs),\n",
        "                nn.ReLU(inplace=True),\n",
        "            ),\n",
        "        )\n",
        "    \n",
        "    def down(self, x):\n",
        "        cache = []\n",
        "        for block in self.down_blocks:\n",
        "            x = block(x)\n",
        "            cache.append(x)\n",
        "        return x, cache\n",
        "    \n",
        "    def up(self, x, down_cache):\n",
        "        for down_index, up in reversed(list(enumerate(self.up_blocks))):\n",
        "            transpose_conv, conv = up\n",
        "            low_level_info = down_cache[down_index]\n",
        "            x = conv(\n",
        "                self.concat(low_level_info, transpose_conv(x))\n",
        "            )\n",
        "        return x\n",
        "    \n",
        "    @staticmethod\n",
        "    def concat(a, b):\n",
        "        return torch.cat((a, b), dim=1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x, down_cache = self.down(x)\n",
        "        x = self.up(x, down_cache)\n",
        "        x = last_conv(x)\n",
        "        return x\n",
        "\n",
        "        # a = F.relu(self.conv1(x))\n",
        "        # a = self.maxpool(F.relu(self.conv2(a)))\n",
        "\n",
        "        # b = F.relu(self.conv3(a))\n",
        "        # b = self.maxpool(F.relu(self.conv4(b)))\n",
        "\n",
        "        # c = F.relu(self.conv5(b))\n",
        "        # c = self.maxpool(F.relu(self.conv6(c)))\n",
        "\n",
        "        # d = F.relu(self.conv7(c))\n",
        "        # d = self.maxpool(F.relu(self.conv8(d)))\n",
        "\n",
        "        # e = F.relu(self.conv9(d))\n",
        "        # e = self.maxpool(F.relu(self.conv10(e)))\n",
        "\n",
        "        # f = self.upconv1(e)\n",
        "        # f = torch.cat((d,f),dim=1)\n",
        "        # f = F.relu(self.conv11(f))\n",
        "        # f = F.relu(self.conv12(f))\n",
        "\n",
        "        # g = self.upconv1(f)\n",
        "        # g = torch.cat((c,g),dim=1)\n",
        "        # g = F.relu(self.conv13(g))\n",
        "        # g = F.relu(self.conv14(g))\n",
        "\n",
        "        # h = self.upconv1(g)\n",
        "        # h = torch.cat((b,h),dim=1)\n",
        "        # h = F.relu(self.conv15(h))\n",
        "        # h = F.relu(self.conv16(h))\n",
        "\n",
        "        # i = self.upconv1(h)\n",
        "        # i = torch.cat((a,i),dim=1)\n",
        "        # i = F.relu(self.conv17(i))\n",
        "        # i = F.relu(self.conv18(i))\n",
        "\n",
        "        # j = self.conv1(i)\n",
        "        # return j\n",
        "\n",
        "    def visualize(self, show=True):\n",
        "\n",
        "        @dataclass\n",
        "        class Block:\n",
        "            # string representation\n",
        "            s: str\n",
        "            # x position of the left arrow if one exists\n",
        "            arr_left: int = 0\n",
        "            # x position of the right arrow if one exists\n",
        "            arr_right: int = 0\n",
        "            \n",
        "            def __str__(self):\n",
        "                return self.s\n",
        "\n",
        "            @property\n",
        "            def w(self):\n",
        "                \"\"\"width\"\"\"\n",
        "                return width(self.s)\n",
        "\n",
        "        RIGHT = '→'\n",
        "        DOWN = '↓'\n",
        "        SQUARE = '■'\n",
        "        HOLLOW_SQUARE = '□'\n",
        "        UP = '↑'\n",
        "        CONV = f' {RIGHT} '\n",
        "        CONV_WS = ' '*len(CONV)\n",
        "\n",
        "        def down_block(in_ch, out_ch, with_up_conv=False):\n",
        "            in_ch = str(in_ch)\n",
        "            out_ch = str(out_ch)\n",
        "            w_thinner = len(in_ch) if len(in_ch) % 2 == 1 else len(in_ch) + 1\n",
        "            w_thicker = w_thinner * 2\n",
        "\n",
        "            in_ch_str = str(in_ch) + ' '*(w_thinner - len(in_ch))\n",
        "            out_ch_str = str(out_ch) + ' '*(w_thicker - len(out_ch))\n",
        "            \n",
        "            line_numbers = in_ch_str + CONV_WS + out_ch_str + CONV_WS + out_ch_str\n",
        "            line_squares = SQUARE*w_thinner + CONV + SQUARE*w_thicker + CONV + SQUARE*w_thicker\n",
        "\n",
        "            w = len(line_squares)\n",
        "\n",
        "            line_arrows = (' '*(w_thinner // 2)) + DOWN\n",
        "            line_arrows_remaining = w - len(line_arrows)\n",
        "            if with_up_conv:\n",
        "                up_and_rest = UP + ' '*(w_thicker // 2)\n",
        "                line_arrows += (' '*(line_arrows_remaining - len(up_and_rest))) + up_and_rest\n",
        "            else:\n",
        "                line_arrows += (' ' * (w - w_thinner // 2 - 1))\n",
        "            return Block(\n",
        "                '\\n'.join((line_arrows, line_numbers, line_squares)),\n",
        "                arr_left=w_thinner//2 + 1,\n",
        "                arr_right=w_thicker//2 + 1,\n",
        "            )\n",
        "        \n",
        "        def up_block(in_ch):\n",
        "            in_ch = str(in_ch)\n",
        "            w_layer = len(in_ch) if len(in_ch) % 2 == 1 else len(in_ch) + 1\n",
        "            w_layer_half = w_layer // 2\n",
        "            in_ch_str = str(in_ch) + ' '*(w_layer - len(in_ch))\n",
        "            line_numbers = in_ch_str + ' '*w_layer + CONV_WS + in_ch_str + CONV_WS + in_ch_str\n",
        "            line_squares = HOLLOW_SQUARE*w_layer + SQUARE*w_layer + CONV + SQUARE*w_layer + CONV + SQUARE*w_layer\n",
        "            line_arrows = (' '*(len(line_squares) - w_layer_half - 1)) + UP + ' '*(w_layer_half - 1)\n",
        "            return Block(\n",
        "                '\\n'.join((line_arrows, line_numbers, line_squares)),\n",
        "                # arr_left=w_layer,\n",
        "                arr_right=w_layer_half + 1,\n",
        "            )\n",
        "\n",
        "        def width(block: str):\n",
        "            return len(block.splitlines()[0])\n",
        "        \n",
        "        def pad(block, pos: str, amount: int):\n",
        "            block = str(block)\n",
        "            padding = ' ' * amount\n",
        "            if pos == \"front\":\n",
        "                f = lambda line: padding + line\n",
        "            elif pos == \"back\":\n",
        "                f = lambda line: line + padding\n",
        "            # elif pos == \"both\":\n",
        "            #     f = lambda line: padding + line + padding\n",
        "            return '\\n'.join([f(line) for line in block.splitlines()])\n",
        "        \n",
        "        def blocks_joined(*blocks):\n",
        "            return '\\n'.join([\n",
        "                ''.join(line_parts) \n",
        "                for line_parts in zip(*[\n",
        "                    str(block).splitlines() \n",
        "                    for block in blocks\n",
        "                ])\n",
        "            ])\n",
        "\n",
        "        \n",
        "        visualization = ''\n",
        "        is_bottom = True\n",
        "        up = Block('')\n",
        "        for i in reversed(range(self.depth)):\n",
        "            in_ch = self.tensor_depths[i - 1] if i > 0 else self.in_channels\n",
        "            out_ch = self.tensor_depths[i]  # if i > 0 else self.out_channels\n",
        "            down = down_block(in_ch, out_ch, with_up_conv=is_bottom)\n",
        "\n",
        "            if is_bottom:\n",
        "                visualization += str(down)\n",
        "                # There is only 1 bottom horizontal \"layer\".\n",
        "                is_bottom = False\n",
        "                prev_down = down\n",
        "                prev_up = up\n",
        "                continue\n",
        "            \n",
        "            up = up_block(out_ch)\n",
        "\n",
        "            # pad exisiting visualization:\n",
        "            # - front: how much new down block protrudes last down block\n",
        "            # - back: how much new up block protrudes last up block\n",
        "            pad_front = down.w - down.arr_right - prev_down.arr_left + 1\n",
        "            pad_back = up.w - up.arr_right - prev_up.arr_left - 1\n",
        "            visualization = pad(visualization, 'front', pad_front)\n",
        "            visualization = pad(visualization, 'back', pad_back)\n",
        "            w_vis = width(visualization)\n",
        "\n",
        "            inbetween_space = w_vis - down.w - up.w\n",
        "            new_horizontal_layer = blocks_joined(\n",
        "                pad(down, 'back', inbetween_space),\n",
        "                up\n",
        "            )\n",
        "            visualization = new_horizontal_layer + '\\n' + visualization\n",
        "            \n",
        "            prev_down = down\n",
        "            prev_up = up\n",
        "\n",
        "        visualization = f'UNet, depth={self.depth}\\n' + visualization\n",
        "        if show:\n",
        "            print(visualization)\n",
        "\n",
        "model = UNet()\n",
        "model.visualize()"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "UNet, depth=5\n",
            "↓                                                                                                                                   ↑\n",
            "1   64   64                                                                                                         64       64    64 \n",
            "■ → ■■ → ■■                                                                                                         □□□■■■ → ■■■ → ■■■\n",
            "         ↓                                                                                                            ↑              \n",
            "        64    128      128                                                                            128      128   128              \n",
            "        ■■■ → ■■■■■■ → ■■■■■■                                                                         □□□■■■ → ■■■ → ■■■              \n",
            "                         ↓                                                                              ↑                            \n",
            "                        128   256      256                                              256      256   256                            \n",
            "                        ■■■ → ■■■■■■ → ■■■■■■                                           □□□■■■ → ■■■ → ■■■                            \n",
            "                                         ↓                                                ↑                                          \n",
            "                                        256   512      512                512      512   512                                          \n",
            "                                        ■■■ → ■■■■■■ → ■■■■■■             □□□■■■ → ■■■ → ■■■                                          \n",
            "                                                         ↓               ↑                                                           \n",
            "                                                        512   1024     1024                                                          \n",
            "                                                        ■■■ → ■■■■■■ → ■■■■■■                                                        \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5v77HlMJZPv9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# TRAIN FUNCTION\n",
        "def train_model(model, criterion, optimizer, scheduler, num_epochs=25):\n",
        "    since = time.time()\n",
        "\n",
        "    best_model_wts = copy.deepcopy(model.state_dict())\n",
        "    best_acc = 0.0\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        print('Epoch {}/{}'.format(epoch+1, num_epochs))\n",
        "        print('-' * 10)\n",
        "\n",
        "        # Each epoch has a training and validation phase\n",
        "        for phase in ['train', 'val']:\n",
        "            if phase == 'train':\n",
        "                model.train()  # Set model to training mode\n",
        "            else:\n",
        "                model.eval()   # Set model to evaluate mode\n",
        "\n",
        "            running_loss = 0.0\n",
        "            running_corrects = 0\n",
        "\n",
        "            # Iterate over data.\n",
        "            for inputs, labels in dataloaders[phase]:\n",
        "                inputs = inputs.to(device)\n",
        "                labels = labels.to(device)\n",
        "\n",
        "                # zero the parameter gradients\n",
        "                optimizer.zero_grad()\n",
        "\n",
        "                # forward\n",
        "                # track history if only in train\n",
        "                with torch.set_grad_enabled(phase == 'train'):\n",
        "                    outputs = model(inputs)\n",
        "                    _, preds = torch.max(outputs, 1)\n",
        "                    loss = criterion(outputs, labels)\n",
        "\n",
        "                    # backward + optimize only if in training phase\n",
        "                    if phase == 'train':\n",
        "                        loss.backward()\n",
        "                        optimizer.step()\n",
        "\n",
        "                # statistics\n",
        "                running_loss += loss.item() * inputs.size(0)\n",
        "                running_corrects += torch.sum(preds == labels.data)\n",
        "            if phase == 'train':\n",
        "                scheduler.step()\n",
        "\n",
        "            epoch_loss = running_loss / dataset_sizes[phase]\n",
        "            epoch_acc = running_corrects.double() / dataset_sizes[phase]\n",
        "\n",
        "            print('{} Loss: {:.4f} Acc: {:.4f}'.format(\n",
        "                phase, epoch_loss, epoch_acc))\n",
        "\n",
        "            # deep copy the model\n",
        "            if phase == 'val' and epoch_acc > best_acc:\n",
        "                best_acc = epoch_acc\n",
        "                best_model_wts = copy.deepcopy(model.state_dict())\n",
        "\n",
        "        print()\n",
        "\n",
        "    time_elapsed = time.time() - since\n",
        "    print('Training complete in {:.0f}m {:.0f}s'.format(\n",
        "        time_elapsed // 60, time_elapsed % 60))\n",
        "    print('Best val Acc: {:4f}'.format(best_acc))\n",
        "\n",
        "    # load best model weights\n",
        "    model.load_state_dict(best_model_wts)\n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4QREZFRNZSOh",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "57185d84-fd38-4f17-e4e5-b1dc355f6a87"
      },
      "source": [
        "model = model.to(device)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# Observe that all parameters are being optimized\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n",
        "\n",
        "# Decay LR by a factor of 0.1 every 7 epochs\n",
        "exp_lr_scheduler = lr_scheduler.StepLR(optimizer, step_size=7, gamma=0.1)\n",
        "\n",
        "model = train_model(model, criterion, optimizer, exp_lr_scheduler,\n",
        "                       num_epochs=25)"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/25\n",
            "----------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-29-ede3f310e8ff>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m model = train_model(model, criterion, optimizer, exp_lr_scheduler,\n\u001b[0;32m---> 12\u001b[0;31m                        num_epochs=25)\n\u001b[0m",
            "\u001b[0;32m<ipython-input-28-f2b4d52379ed>\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(model, criterion, optimizer, scheduler, num_epochs)\u001b[0m\n\u001b[1;32m     30\u001b[0m                 \u001b[0;31m# track history if only in train\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_grad_enabled\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mphase\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'train'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m                     \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m                     \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpreds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m                     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    539\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    540\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 541\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    542\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    543\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-27-76d01f447d5c>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    157\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    158\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 159\u001b[0;31m         \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdown_cache\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdown\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    160\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdown_cache\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    161\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlast_conv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-27-76d01f447d5c>\u001b[0m in \u001b[0;36mdown\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    139\u001b[0m         \u001b[0mcache\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mblock\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdown_blocks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 141\u001b[0;31m             \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mblock\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    142\u001b[0m             \u001b[0mcache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcache\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    539\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    540\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 541\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    542\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    543\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     90\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_modules\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 92\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    539\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    540\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 541\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    542\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    543\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    343\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    344\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 345\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv2d_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    346\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    347\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mConv3d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_ConvNd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36mconv2d_forward\u001b[0;34m(self, input, weight)\u001b[0m\n\u001b[1;32m    340\u001b[0m                             _pair(0), self.dilation, self.groups)\n\u001b[1;32m    341\u001b[0m         return F.conv2d(input, weight, self.bias, self.stride,\n\u001b[0;32m--> 342\u001b[0;31m                         self.padding, self.dilation, self.groups)\n\u001b[0m\u001b[1;32m    343\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    344\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: Given groups=1, weight of size 64 1 3 3, expected input[100, 3, 64, 85] to have 1 channels, but got 3 channels instead"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XaWOYb1CZep2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# VISUALIZE PREDICTION\n",
        "def visualize(model):\n",
        "    with torch.no_grad():\n",
        "        for data in dataloaders['val']:\n",
        "            inputs, labels = data\n",
        "            inputs = inputs.to(device)\n",
        "            labels = labels.to(device)\n",
        "            outputs = model(inputs)\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            \n",
        "            print(predicted)\n",
        "\n",
        "            pred_plot = predicted[0,:,:].cpu().numpy()\n",
        "            plt.imshow(pred_plot)\n",
        "            plt.show()\n",
        "\n",
        "            break\n",
        "    \n",
        "visualize(model)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sLqDLY7o54o1",
        "colab_type": "text"
      },
      "source": [
        "## 8.2\n",
        "Once you have done that, we want you to redesign a network where you remove to reinjection link (grey arrow on the drawing). You can remove the both from your choice just try and tell us if it's still working and why."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yDG04rye54o4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#TODO"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_9yesinb54pF",
        "colab_type": "text"
      },
      "source": [
        "## 8.3 BONUSTOCOME"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A2H22yFC54pI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}