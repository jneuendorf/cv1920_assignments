{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Dw2Lkqb8S7vq"
   },
   "source": [
    "# Assignment 9\n",
    "\n",
    "Neural need huge amount of data to be able to perform well. Huge amount of data means huge computation power... To bypass the fact that we don't own this kind of machine, we will us the transfer leaning. By using a pretrained network (usually on ImageNet) and train it a little bit, we can avoid most of the computationnal power needed to perform our task. We will work on the ResNet network (https://arxiv.org/pdf/1512.03385.pdf) designed in 2014. \n",
    "Then, because we know you all have a degree in medicine, we will try our luck bu doing some! We will then retrain the last layer of the network to be able to recognize leopard and cheetah. The cheetah mini database is in the image folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-10T12:50:47.089693Z",
     "start_time": "2020-01-10T12:50:45.623080Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "ZfW8aon7S7vs",
    "outputId": "d04707dc-8506-45d1-f3d5-821ca18df122"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<module 'torch' from '/usr/local/lib/python3.6/dist-packages/torch/__init__.py'>\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function, division\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "import numpy as np\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import os\n",
    "import copy\n",
    "\n",
    "print(torch)\n",
    "\n",
    "plt.ion()   # interactive mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "FIT39nfmVGCL",
    "outputId": "a764c38a-07d6-4ae9-fd92-422563ce392d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-10T12:50:47.130783Z",
     "start_time": "2020-01-10T12:50:47.092751Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 102
    },
    "colab_type": "code",
    "id": "5j79HAapS7vv",
    "outputId": "07d438bb-58be-4157-eff8-f53af332d75c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n",
      "Loaded 450 images under train\n",
      "Loaded 162 images under val\n",
      "Classes: \n",
      "['cheetah', 'leopard', 'unknown']\n"
     ]
    }
   ],
   "source": [
    "data_dir = '/content/drive/My Drive/Colab Notebooks/images/cheetah_data_mini'\n",
    "TRAIN = 'train'\n",
    "TEST = 'val'\n",
    "\n",
    "# ResNet Takes 224x224 images as input, so we resize all of them\n",
    "data_transforms = {\n",
    "    TRAIN: transforms.Compose([\n",
    "        transforms.RandomResizedCrop(224),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "    TEST: transforms.Compose([\n",
    "        transforms.Resize(256),\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "}\n",
    "\n",
    "image_datasets = {\n",
    "    x: datasets.ImageFolder(\n",
    "        os.path.join(data_dir, x), \n",
    "        transform=data_transforms[x]\n",
    "    )\n",
    "    for x in [TRAIN, TEST]\n",
    "}\n",
    "\n",
    "dataloaders = {\n",
    "    x: torch.utils.data.DataLoader(\n",
    "        image_datasets[x], batch_size=4,\n",
    "        shuffle=True, num_workers=4\n",
    "    )\n",
    "    for x in [TRAIN, TEST]\n",
    "}\n",
    "\n",
    "dataset_sizes = {x: len(image_datasets[x]) for x in [TRAIN, TEST]}\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "\n",
    "for x in [TRAIN, TEST]:\n",
    "    print(\"Loaded {} images under {}\".format(dataset_sizes[x], x))\n",
    "    \n",
    "print(\"Classes: \")\n",
    "class_names = image_datasets[TRAIN].classes\n",
    "print(image_datasets[TRAIN].classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-10T12:50:47.176999Z",
     "start_time": "2020-01-10T12:50:47.136283Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 182
    },
    "colab_type": "code",
    "id": "huSB861FS7vx",
    "outputId": "d8698cca-4068-4201-ac26-b0f90a119091"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 228, 906])\n",
      "torch.Size([3, 228])\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAV0AAAByCAYAAADwBQLgAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def imshow(inp, title=None):\n",
    "    inp = inp.numpy().transpose((1, 2, 0))\n",
    "    # plt.figure(figsize=(10, 10))\n",
    "    plt.axis('off')\n",
    "    plt.imshow(inp)\n",
    "    if title is not None:\n",
    "        plt.title(title)\n",
    "    plt.pause(0.001)\n",
    "\n",
    "def show_databatch(inputs, classes):\n",
    "    out = torchvision.utils.make_grid(inputs)\n",
    "    print(out.shape)\n",
    "    print(out[:,:,15].shape)\n",
    "    imshow(out, title=[class_names[x] for x in classes])\n",
    "\n",
    "\n",
    "# Get a batch of training data\n",
    "inputs, classes = next(iter(dataloaders[TRAIN]))\n",
    "show_databatch(inputs, classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "mHKYy-oSS7v0"
   },
   "source": [
    "## Pretrained network\n",
    "\n",
    "Now load a network pre-trained on Imagenet and classify the validation data. You can import a pretrained model directly from pytorch with models.resnet18(pretrained=True). The labels are already used in ImageNet so try to recognize the database directly using the output of the pretrained network on the validation database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-10T12:50:47.845114Z",
     "start_time": "2020-01-10T12:50:47.183496Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "BkUTrxXgS7v0",
    "outputId": "bf2ba496-8cc7-47a4-9ca7-8968a014a24e"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://download.pytorch.org/models/resnet18-5c106cde.pth\" to /root/.cache/torch/checkpoints/resnet18-5c106cde.pth\n",
      "100%|██████████| 44.7M/44.7M [00:01<00:00, 25.8MB/s]\n"
     ]
    }
   ],
   "source": [
    "# NET\n",
    "model_vanilla = torchvision.models.resnet18(pretrained=True)\n",
    "# model_vanilla = model_vanilla.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-10T12:50:47.862655Z",
     "start_time": "2020-01-10T12:50:47.848232Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "mynvIm7_S7v2"
   },
   "outputs": [],
   "source": [
    "for param in model_vanilla.parameters():\n",
    "    param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-10T12:50:47.905410Z",
     "start_time": "2020-01-10T12:50:47.890015Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "vtzbu6u1S7v4"
   },
   "outputs": [],
   "source": [
    "# cheetah = 293; leopard = 288;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-10T12:51:06.966532Z",
     "start_time": "2020-01-10T12:50:47.910742Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "KkZ8IyupS7v5",
    "outputId": "5e19b5c1-3463-4075-c642-02ade04a8398"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 33 %\n"
     ]
    }
   ],
   "source": [
    "# TEST THE NET ON OUR DATASET\n",
    "def switch_class_idx(predicted):\n",
    "    for x in range(predicted.shape[0]):\n",
    "        if predicted[x] == 293:\n",
    "            predicted[x] = 0\n",
    "        elif predicted[x] == 288:\n",
    "            predicted[x] = 1\n",
    "        else:\n",
    "            predicted[x] = 2\n",
    "    return predicted\n",
    "\n",
    "def val_pretrained(model):\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for data in dataloaders[TEST]:\n",
    "            inputs, labels = data\n",
    "            # inputs = inputs.to(device)\n",
    "            # labels = labels.to(device)\n",
    "            outputs = model(inputs)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            # print(predicted)\n",
    "            predicted = switch_class_idx(predicted)\n",
    "            #print(labels, predicted)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "    print('Accuracy: %d %%' % (\n",
    "        100 * correct / total))\n",
    "\n",
    "val_pretrained(model_vanilla)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "hWiRfJR1S7v7"
   },
   "source": [
    "## Transfer learning\n",
    "\n",
    "The pre-trained network can now be further trained with our data. Replace the last layer in the network with a fully connected Layer with 3 outputs for our classes cheetah, leopard and unknown. Then train the last layer of the network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-10T12:59:18.824842Z",
     "start_time": "2020-01-10T12:59:18.775586Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "JWhtGNENS7v8"
   },
   "outputs": [],
   "source": [
    "import copy\n",
    "\n",
    "\n",
    "def train_model(model, criterion, optimizer, scheduler, num_epochs=25):\n",
    "    since = time.time()\n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    best_acc = 0.0\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        print('Epoch {}/{}'.format(epoch+1, num_epochs))\n",
    "        print('-' * 10)\n",
    "\n",
    "        # Each epoch has a training and validation phase\n",
    "        for phase in [TRAIN, TEST]:\n",
    "            if phase == TRAIN:\n",
    "                model.train()  # Set model to training mode\n",
    "            else:\n",
    "                model.eval()   # Set model to evaluate mode\n",
    "\n",
    "            running_loss = 0.0\n",
    "            running_corrects = 0\n",
    "\n",
    "            # Iterate over data.\n",
    "            for inputs, labels in dataloaders[phase]:\n",
    "                # inputs = inputs.to(device)\n",
    "                # labels = labels.to(device)\n",
    "                \n",
    "                # zero the parameter gradients\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                # forward\n",
    "                # track history if only in train\n",
    "                with torch.set_grad_enabled(phase == TRAIN):\n",
    "                    outputs = model(inputs)\n",
    "                    _, preds = torch.max(outputs, 1)\n",
    "                    loss = criterion(outputs, labels)\n",
    "                    # backward + optimize only if in training phase\n",
    "                    if phase == TRAIN:\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "\n",
    "                # statistics\n",
    "                running_loss += loss.item() * inputs.size(0)\n",
    "                running_corrects += torch.sum(preds == labels.data)\n",
    "                    \n",
    "            if phase == TRAIN:\n",
    "                scheduler.step()\n",
    "\n",
    "            epoch_loss = running_loss / dataset_sizes[phase]\n",
    "            epoch_acc = running_corrects.double() / dataset_sizes[phase]\n",
    "\n",
    "            print('{} Loss: {:.4f} Acc: {:.4f}'.format(\n",
    "                phase, epoch_loss, epoch_acc))\n",
    "\n",
    "            # deep copy the model\n",
    "            if phase == 'val' and epoch_acc > best_acc:\n",
    "                best_acc = epoch_acc\n",
    "                best_model_wts = copy.deepcopy(model.state_dict())\n",
    "\n",
    "        print()\n",
    "\n",
    "    time_elapsed = time.time() - since\n",
    "    print('Training complete in {:.0f}m {:.0f}s'.format(\n",
    "        time_elapsed // 60, time_elapsed % 60))\n",
    "\n",
    "    # load best model weights\n",
    "    model.load_state_dict(best_model_wts)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-10T15:24:54.060907Z",
     "start_time": "2020-01-10T15:24:53.411054Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "r8GTdG8BS7v9"
   },
   "outputs": [],
   "source": [
    "# FEATURE EXTRACTING\n",
    "model_extract = torchvision.models.resnet18(pretrained=True)\n",
    "for param in model_extract.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "# Parameters of newly constructed modules have requires_grad=True by default\n",
    "num_ftrs = model_extract.fc.in_features\n",
    "model_extract.fc = nn.Linear(num_ftrs, 3)\n",
    "# model_extract = model_extract.to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer_ext = optim.SGD(model_extract.fc.parameters(), lr=.0001, momentum=0.9)\n",
    "\n",
    "# Decay LR by a factor\n",
    "exp_lr_scheduler = lr_scheduler.StepLR(optimizer_ext, step_size=5, gamma=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-10T15:52:40.417855Z",
     "start_time": "2020-01-10T15:24:55.106853Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "IpcfvyRjS7v_",
    "outputId": "d06aecc9-ec72-4b26-d8cb-520f31ef8cfe"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "----------\n",
      "train Loss: 0.6311 Acc: 0.8111\n",
      "val Loss: 0.8420 Acc: 0.5679\n",
      "\n",
      "Epoch 2/50\n",
      "----------\n",
      "train Loss: 0.6781 Acc: 0.7467\n",
      "val Loss: 0.8289 Acc: 0.6420\n",
      "\n",
      "Epoch 3/50\n",
      "----------\n",
      "train Loss: 0.6274 Acc: 0.7756\n",
      "val Loss: 0.8256 Acc: 0.6111\n",
      "\n",
      "Epoch 4/50\n",
      "----------\n",
      "train Loss: 0.6341 Acc: 0.7778\n",
      "val Loss: 0.7828 Acc: 0.7160\n",
      "\n",
      "Epoch 5/50\n",
      "----------\n",
      "train Loss: 0.6181 Acc: 0.7978\n",
      "val Loss: 0.8357 Acc: 0.6049\n",
      "\n",
      "Epoch 6/50\n",
      "----------\n",
      "train Loss: 0.6768 Acc: 0.7400\n",
      "val Loss: 0.8089 Acc: 0.6111\n",
      "\n",
      "Epoch 7/50\n",
      "----------\n",
      "train Loss: 0.6442 Acc: 0.7822\n",
      "val Loss: 0.8537 Acc: 0.6235\n",
      "\n",
      "Epoch 8/50\n",
      "----------\n",
      "train Loss: 0.6708 Acc: 0.7489\n",
      "val Loss: 0.8059 Acc: 0.6235\n",
      "\n",
      "Epoch 9/50\n",
      "----------\n",
      "train Loss: 0.6500 Acc: 0.7556\n",
      "val Loss: 0.8358 Acc: 0.5926\n",
      "\n",
      "Epoch 10/50\n",
      "----------\n",
      "train Loss: 0.6116 Acc: 0.7889\n",
      "val Loss: 0.8594 Acc: 0.5617\n",
      "\n",
      "Epoch 11/50\n",
      "----------\n",
      "train Loss: 0.6794 Acc: 0.7622\n",
      "val Loss: 0.8166 Acc: 0.6049\n",
      "\n",
      "Epoch 12/50\n",
      "----------\n",
      "train Loss: 0.6256 Acc: 0.8044\n",
      "val Loss: 0.8217 Acc: 0.6358\n",
      "\n",
      "Epoch 13/50\n",
      "----------\n",
      "train Loss: 0.6823 Acc: 0.7444\n",
      "val Loss: 0.8338 Acc: 0.5802\n",
      "\n",
      "Epoch 14/50\n",
      "----------\n",
      "train Loss: 0.6390 Acc: 0.7556\n",
      "val Loss: 0.8205 Acc: 0.6049\n",
      "\n",
      "Epoch 15/50\n",
      "----------\n",
      "train Loss: 0.6443 Acc: 0.7689\n",
      "val Loss: 0.7874 Acc: 0.6358\n",
      "\n",
      "Epoch 16/50\n",
      "----------\n",
      "train Loss: 0.6234 Acc: 0.8044\n",
      "val Loss: 0.8591 Acc: 0.5802\n",
      "\n",
      "Epoch 17/50\n",
      "----------\n",
      "train Loss: 0.6957 Acc: 0.7200\n",
      "val Loss: 0.8644 Acc: 0.5494\n",
      "\n",
      "Epoch 18/50\n",
      "----------\n",
      "train Loss: 0.6864 Acc: 0.7578\n",
      "val Loss: 0.8773 Acc: 0.6296\n",
      "\n",
      "Epoch 19/50\n",
      "----------\n",
      "train Loss: 0.6635 Acc: 0.7422\n",
      "val Loss: 0.8298 Acc: 0.6420\n",
      "\n",
      "Epoch 20/50\n",
      "----------\n",
      "train Loss: 0.6181 Acc: 0.8222\n",
      "val Loss: 0.8428 Acc: 0.5617\n",
      "\n",
      "Epoch 21/50\n",
      "----------\n",
      "train Loss: 0.6408 Acc: 0.8000\n",
      "val Loss: 0.8551 Acc: 0.6173\n",
      "\n",
      "Epoch 22/50\n",
      "----------\n",
      "train Loss: 0.6245 Acc: 0.7822\n",
      "val Loss: 0.8289 Acc: 0.6420\n",
      "\n",
      "Epoch 23/50\n",
      "----------\n",
      "train Loss: 0.6334 Acc: 0.7844\n",
      "val Loss: 0.8490 Acc: 0.5679\n",
      "\n",
      "Epoch 24/50\n",
      "----------\n",
      "train Loss: 0.6359 Acc: 0.7800\n",
      "val Loss: 0.8720 Acc: 0.5802\n",
      "\n",
      "Epoch 25/50\n",
      "----------\n",
      "train Loss: 0.7109 Acc: 0.7311\n",
      "val Loss: 0.8168 Acc: 0.5988\n",
      "\n",
      "Epoch 26/50\n",
      "----------\n",
      "train Loss: 0.6663 Acc: 0.7689\n",
      "val Loss: 0.8117 Acc: 0.6235\n",
      "\n",
      "Epoch 27/50\n",
      "----------\n",
      "train Loss: 0.6699 Acc: 0.7556\n",
      "val Loss: 0.8516 Acc: 0.6173\n",
      "\n",
      "Epoch 28/50\n",
      "----------\n",
      "train Loss: 0.6583 Acc: 0.7800\n",
      "val Loss: 0.8211 Acc: 0.6667\n",
      "\n",
      "Epoch 29/50\n",
      "----------\n",
      "train Loss: 0.6489 Acc: 0.7911\n",
      "val Loss: 0.8052 Acc: 0.5988\n",
      "\n",
      "Epoch 30/50\n",
      "----------\n",
      "train Loss: 0.6254 Acc: 0.7822\n",
      "val Loss: 0.8115 Acc: 0.6235\n",
      "\n",
      "Epoch 31/50\n",
      "----------\n",
      "train Loss: 0.6392 Acc: 0.7822\n",
      "val Loss: 0.8556 Acc: 0.5864\n",
      "\n",
      "Epoch 32/50\n",
      "----------\n",
      "train Loss: 0.6247 Acc: 0.7867\n",
      "val Loss: 0.8417 Acc: 0.5679\n",
      "\n",
      "Epoch 33/50\n",
      "----------\n",
      "train Loss: 0.6284 Acc: 0.8000\n",
      "val Loss: 0.8435 Acc: 0.5679\n",
      "\n",
      "Epoch 34/50\n",
      "----------\n",
      "train Loss: 0.6384 Acc: 0.7644\n",
      "val Loss: 0.8411 Acc: 0.6173\n",
      "\n",
      "Epoch 35/50\n",
      "----------\n",
      "train Loss: 0.6411 Acc: 0.7956\n",
      "val Loss: 0.8113 Acc: 0.6543\n",
      "\n",
      "Epoch 36/50\n",
      "----------\n",
      "train Loss: 0.6672 Acc: 0.7489\n",
      "val Loss: 0.8608 Acc: 0.5988\n",
      "\n",
      "Epoch 37/50\n",
      "----------\n",
      "train Loss: 0.6572 Acc: 0.7400\n",
      "val Loss: 0.8295 Acc: 0.6049\n",
      "\n",
      "Epoch 38/50\n",
      "----------\n",
      "train Loss: 0.6390 Acc: 0.7600\n",
      "val Loss: 0.8409 Acc: 0.5988\n",
      "\n",
      "Epoch 39/50\n",
      "----------\n",
      "train Loss: 0.6744 Acc: 0.7556\n",
      "val Loss: 0.7929 Acc: 0.6790\n",
      "\n",
      "Epoch 40/50\n",
      "----------\n",
      "train Loss: 0.6136 Acc: 0.7933\n",
      "val Loss: 0.8125 Acc: 0.6420\n",
      "\n",
      "Epoch 41/50\n",
      "----------\n",
      "train Loss: 0.6619 Acc: 0.7600\n",
      "val Loss: 0.8426 Acc: 0.5926\n",
      "\n",
      "Epoch 42/50\n",
      "----------\n",
      "train Loss: 0.6175 Acc: 0.8200\n",
      "val Loss: 0.8284 Acc: 0.6111\n",
      "\n",
      "Epoch 43/50\n",
      "----------\n",
      "train Loss: 0.6538 Acc: 0.7511\n",
      "val Loss: 0.8680 Acc: 0.5432\n",
      "\n",
      "Epoch 44/50\n",
      "----------\n",
      "train Loss: 0.6684 Acc: 0.7556\n",
      "val Loss: 0.8988 Acc: 0.5247\n",
      "\n",
      "Epoch 45/50\n",
      "----------\n",
      "train Loss: 0.6533 Acc: 0.7578\n",
      "val Loss: 0.8186 Acc: 0.6111\n",
      "\n",
      "Epoch 46/50\n",
      "----------\n",
      "train Loss: 0.6536 Acc: 0.7422\n",
      "val Loss: 0.8857 Acc: 0.5494\n",
      "\n",
      "Epoch 47/50\n",
      "----------\n",
      "train Loss: 0.6664 Acc: 0.7533\n",
      "val Loss: 0.8381 Acc: 0.5864\n",
      "\n",
      "Epoch 48/50\n",
      "----------\n",
      "train Loss: 0.6553 Acc: 0.7711\n",
      "val Loss: 0.8346 Acc: 0.5864\n",
      "\n",
      "Epoch 49/50\n",
      "----------\n",
      "train Loss: 0.6479 Acc: 0.7578\n",
      "val Loss: 0.8253 Acc: 0.5988\n",
      "\n",
      "Epoch 50/50\n",
      "----------\n",
      "train Loss: 0.6402 Acc: 0.7556\n",
      "val Loss: 0.8227 Acc: 0.5926\n",
      "\n",
      "Training complete in 38m 26s\n"
     ]
    }
   ],
   "source": [
    "model_extract = train_model(model_extract, criterion, optimizer_ext,\n",
    "                         exp_lr_scheduler, num_epochs=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-10T15:53:03.447683Z",
     "start_time": "2020-01-10T15:52:40.443340Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "lyQ4twoSS7wB",
    "outputId": "d1db9dfb-ac52-4916-ef96-c8b9285ceea4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 71 %\n"
     ]
    }
   ],
   "source": [
    "def val_extract(model):\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for data in dataloaders[TEST]:\n",
    "            inputs, labels = data\n",
    "            # inputs = inputs.to(device)\n",
    "            # labels = labels.to(device)\n",
    "            outputs = model(inputs)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            #print(labels, predicted)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "    print('Accuracy: %d %%' % (\n",
    "        100 * correct / total))\n",
    "    \n",
    "val_extract(model_extract)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bAVIrNYqS7wC"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Copy of 09_PyTorch_TransferLearning_Jim.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
