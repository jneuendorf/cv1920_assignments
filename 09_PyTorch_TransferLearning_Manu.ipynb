{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 9\n",
    "\n",
    "Neural need huge amount of data to be able to perform well. Huge amount of data means huge computation power... To bypass the fact that we don't own this kind of machine, we will us the transfer leaning. By using a pretrained network (usually on ImageNet) and train it a little bit, we can avoid most of the computationnal power needed to perform our task. We will work on the ResNet network (https://arxiv.org/pdf/1512.03385.pdf) designed in 2014. \n",
    "Then, because we know you all have a degree in medicine, we will try our luck bu doing some! We will then retrain the last layer of the network to be able to recognize leopard and cheetah. The cheetah mini database is in the image folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-09T13:21:59.271000Z",
     "start_time": "2020-01-09T13:21:57.110322Z"
    }
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function, division\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "import numpy as np\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import os\n",
    "import copy\n",
    "\n",
    "\n",
    "plt.ion()   # interactive mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-09T13:21:59.333290Z",
     "start_time": "2020-01-09T13:21:59.276747Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 450 images under train\n",
      "Loaded 162 images under val\n",
      "Classes: \n",
      "['cheetah', 'leopard', 'unknown']\n"
     ]
    }
   ],
   "source": [
    "data_dir = 'cheetah_data_mini'\n",
    "TRAIN = 'train'\n",
    "TEST = 'val'\n",
    "\n",
    "# ResNet Takes 224x224 images as input, so we resize all of them\n",
    "data_transforms = {\n",
    "    TRAIN: transforms.Compose([\n",
    "        transforms.RandomResizedCrop(224),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "    TEST: transforms.Compose([\n",
    "        transforms.Resize(256),\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "}\n",
    "\n",
    "image_datasets = {\n",
    "    x: datasets.ImageFolder(\n",
    "        os.path.join(data_dir, x), \n",
    "        transform=data_transforms[x]\n",
    "    )\n",
    "    for x in [TRAIN, TEST]\n",
    "}\n",
    "\n",
    "dataloaders = {\n",
    "    x: torch.utils.data.DataLoader(\n",
    "        image_datasets[x], batch_size=4,\n",
    "        shuffle=True, num_workers=4\n",
    "    )\n",
    "    for x in [TRAIN, TEST]\n",
    "}\n",
    "\n",
    "dataset_sizes = {x: len(image_datasets[x]) for x in [TRAIN, TEST]}\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "for x in [TRAIN, TEST]:\n",
    "    print(\"Loaded {} images under {}\".format(dataset_sizes[x], x))\n",
    "    \n",
    "print(\"Classes: \")\n",
    "class_names = image_datasets[TRAIN].classes\n",
    "print(image_datasets[TRAIN].classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-09T13:21:59.430460Z",
     "start_time": "2020-01-09T13:21:59.355676Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n# Get a batch of training data\\ninputs, classes = next(iter(dataloaders[TRAIN]))\\nshow_databatch(inputs, classes)\\n'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def imshow(inp, title=None):\n",
    "    inp = inp.numpy().transpose((1, 2, 0))\n",
    "    # plt.figure(figsize=(10, 10))\n",
    "    plt.axis('off')\n",
    "    plt.imshow(inp)\n",
    "    if title is not None:\n",
    "        plt.title(title)\n",
    "    plt.pause(0.001)\n",
    "\n",
    "def show_databatch(inputs, classes):\n",
    "    out = torchvision.utils.make_grid(inputs)\n",
    "    print(out.shape)\n",
    "    print(out[:,:,15].shape)\n",
    "    imshow(out, title=[class_names[x] for x in classes])\n",
    "\"\"\"\n",
    "# Get a batch of training data\n",
    "inputs, classes = next(iter(dataloaders[TRAIN]))\n",
    "show_databatch(inputs, classes)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pretrained network\n",
    "\n",
    "Now load a network pre-trained on Imagenet and classify the validation data. You can import a pretrained model directly from pytorch with models.resnet18(pretrained=True). The labels are already used in ImageNet so try to recognize the database directly using the output of the pretrained network on the validation database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-09T13:22:00.746166Z",
     "start_time": "2020-01-09T13:21:59.475906Z"
    }
   },
   "outputs": [],
   "source": [
    "# NET\n",
    "model_vanilla = torchvision.models.resnet18(pretrained=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-09T13:22:00.770483Z",
     "start_time": "2020-01-09T13:22:00.750270Z"
    }
   },
   "outputs": [],
   "source": [
    "for param in model_vanilla.parameters():\n",
    "    param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-09T13:22:00.849540Z",
     "start_time": "2020-01-09T13:22:00.788459Z"
    }
   },
   "outputs": [],
   "source": [
    "# cheetah = 293; leopard = 288;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-09T13:22:20.057384Z",
     "start_time": "2020-01-09T13:22:00.926557Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 35 %\n"
     ]
    }
   ],
   "source": [
    "# TEST THE NET ON OUR DATASET\n",
    "def switch_class_idx(predicted):\n",
    "    for x in range(predicted.shape[0]):\n",
    "        if predicted[x] == 293:\n",
    "            predicted[x] = 0\n",
    "        elif predicted[x] == 288:\n",
    "            predicted[x] = 1\n",
    "        else:\n",
    "            predicted[x] = 2\n",
    "    return predicted\n",
    "\n",
    "def val_pretrained(model):\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for data in dataloaders[TEST]:\n",
    "            images, labels = data\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            #print(predicted)\n",
    "            predicted = switch_class_idx(predicted)\n",
    "            #print(labels, predicted)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "    print('Accuracy: %d %%' % (\n",
    "        100 * correct / total))\n",
    "\n",
    "val_pretrained(model_vanilla)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transfer learning\n",
    "\n",
    "The pre-trained network can now be further trained with our data. Replace the last layer in the network with a fully connected Layer with 3 outputs for our classes cheetah, leopard and unknown. Then train the last layer of the network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-09T13:56:52.609293Z",
     "start_time": "2020-01-09T13:56:52.598693Z"
    }
   },
   "outputs": [],
   "source": [
    "def train_model(model, criterion, optimizer, scheduler, num_epochs=25):\n",
    "    since = time.time()\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
    "        print('-' * 10)\n",
    "        \n",
    "        model.train()\n",
    "\n",
    "        running_loss = 0.0\n",
    "        running_corrects = 0\n",
    "\n",
    "        # Iterate over data.\n",
    "        for inputs, labels in dataloaders[TRAIN]:\n",
    "            \n",
    "            # zero the parameter gradients\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # forward\n",
    "            # track history if only in train\n",
    "            with torch.set_grad_enabled(True):\n",
    "                outputs = model(inputs)\n",
    "                _, preds = torch.max(outputs, 1)\n",
    "                loss = criterion(outputs, labels)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "                # statistics\n",
    "                running_loss += loss.item() * inputs.size(0)\n",
    "                running_corrects += torch.sum(preds == labels.data)\n",
    "                \n",
    "            scheduler.step()\n",
    "\n",
    "            epoch_loss = running_loss / dataset_sizes[TRAIN]\n",
    "            epoch_acc = running_corrects.double() / dataset_sizes[TRAIN]\n",
    "\n",
    "        print('{} Loss: {:.4f} Acc: {:.4f}'.format(\n",
    "            \"TRAIN\", epoch_loss, epoch_acc))\n",
    "\n",
    "        print()\n",
    "\n",
    "    time_elapsed = time.time() - since\n",
    "    print('Training complete in {:.0f}m {:.0f}s'.format(\n",
    "        time_elapsed // 60, time_elapsed % 60))\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-09T13:56:53.428725Z",
     "start_time": "2020-01-09T13:56:52.871451Z"
    }
   },
   "outputs": [],
   "source": [
    "# FEATURE EXTRACTING\n",
    "model_extract = torchvision.models.resnet18(pretrained=True)\n",
    "for param in model_extract.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "# Parameters of newly constructed modules have requires_grad=True by default\n",
    "num_ftrs = model_extract.fc.in_features\n",
    "model_extract.fc = nn.Linear(num_ftrs, 3)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Observe that only parameters of final layer are being optimized as\n",
    "# opposed to before.\n",
    "optimizer_ext = optim.SGD(model_extract.fc.parameters(), lr=0.01, momentum=0.9)\n",
    "\n",
    "# Decay LR by a factor of 0.1 every 7 epochs\n",
    "exp_lr_scheduler = lr_scheduler.StepLR(optimizer_ext, step_size=3, gamma=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-09T14:08:08.006914Z",
     "start_time": "2020-01-09T13:56:53.432281Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/9\n",
      "----------\n",
      "TRAIN Loss: 1.0448 Acc: 0.4156\n",
      "\n",
      "Epoch 1/9\n",
      "----------\n",
      "TRAIN Loss: 1.0447 Acc: 0.4089\n",
      "\n",
      "Epoch 2/9\n",
      "----------\n",
      "TRAIN Loss: 1.0288 Acc: 0.4156\n",
      "\n",
      "Epoch 3/9\n",
      "----------\n",
      "TRAIN Loss: 0.9903 Acc: 0.4333\n",
      "\n",
      "Epoch 4/9\n",
      "----------\n",
      "TRAIN Loss: 0.9911 Acc: 0.4356\n",
      "\n",
      "Epoch 5/9\n",
      "----------\n",
      "TRAIN Loss: 1.0084 Acc: 0.4356\n",
      "\n",
      "Epoch 6/9\n",
      "----------\n",
      "TRAIN Loss: 0.9944 Acc: 0.4222\n",
      "\n",
      "Epoch 7/9\n",
      "----------\n",
      "TRAIN Loss: 1.0030 Acc: 0.4511\n",
      "\n",
      "Epoch 8/9\n",
      "----------\n",
      "TRAIN Loss: 1.0250 Acc: 0.4000\n",
      "\n",
      "Epoch 9/9\n",
      "----------\n",
      "TRAIN Loss: 0.9925 Acc: 0.4356\n",
      "\n",
      "Training complete in 11m 15s\n"
     ]
    }
   ],
   "source": [
    "model_extract = train_model(model_extract, criterion, optimizer_ext,\n",
    "                         exp_lr_scheduler, num_epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-09T14:09:56.776752Z",
     "start_time": "2020-01-09T14:09:37.560069Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 41 %\n"
     ]
    }
   ],
   "source": [
    "def val_extract(model):\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for data in dataloaders[TEST]:\n",
    "            images, labels = data\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            #print(labels, predicted)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "    print('Accuracy: %d %%' % (\n",
    "        100 * correct / total))\n",
    "    \n",
    "val_extract(model_extract)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
